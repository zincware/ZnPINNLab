{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "47456226",
      "metadata": {},
      "source": [
        "### Nomenclature \n",
        "NN      Neural Network  \n",
        "PINN       Physics-Informed Neural Network\n",
        "___\n",
        "___\n",
        "# Background\n",
        "On the first day of the experiment, you learned how to implement and train a neural network using the PyTorch Library.\n",
        "Today, we will apply this knowledge to a more challenging physical problem: the quantum mechanical harmonic oscillator. The task is to train a PINN to predict the time evolution of a system using the initial wavefunction at $t=0$ and the time-dependent Schrodinger equation.\n",
        "Once model training is complete, we inspect its final predictions to ensure they align with the theory both qualitatively and quantitatively. We then expand the complexity of the physical system to approve the network's abilities.\n",
        "\n",
        "To emphasize the physical aspects, this template simplifies the machine learning process by providing pre-prepared data, a model blueprint, and the training algorithm. You only need to implement the logic into the loss functions and execute it. Good luck!\n",
        "___\n",
        "___\n",
        "# Tasks\n",
        "\n",
        "### Implementation \n",
        "This experiment focuses on executing the PINN rather than implementing it.\n",
        "Therefore, large portions of the code are already provided.\n",
        "First, gain an understanding of the model you are working with, and then complete the implementation.\n",
        "\n",
        "1. __Understand code__\n",
        "    1. Visualize imported data.\n",
        "    2. inspect the `prepare_data` function, the `PINN` class and the `execute` function.\n",
        "    3. Take notes for future evaluation.\n",
        "<br><br>\n",
        "\n",
        "2. __Implement Loss__\n",
        "    1. Complete the `compute_boundary_loss` function.\n",
        "    2. Complete the `compute_initial_loss` function.\n",
        "    3. Complete the `compute_physics_informed_loss` function.\n",
        "<br><br>\n",
        "  \n",
        "3. __Verify functionality__\n",
        "    1. execute the network training.\n",
        "    2. Visualize the network prediction using the `AnimationCreator` Class.\n",
        "    3. Have your tutor approve your work before saving the contour plots for future evaluation.\n",
        "       Also animate the solution using the Animator.\n",
        "___\n",
        "### Execution \n",
        "\n",
        "4. __Energy Eigenvalues__ \n",
        "\n",
        "    Goal of this Task is, to compute the energy eigenvalue corresponding to the predicted wavefunction.\n",
        "    <br><br>\n",
        "\n",
        "5. __Diminishing Potential__  \n",
        "\n",
        "    Now we want to explore how the wave function will behave in a diminishing potential.  \n",
        "___\n",
        "___\n",
        "__Note__ for evaluation:\n",
        "\n",
        "When evaluating, it is important to explain the implementation and results obtained.  \n",
        "Be sure to take notes while completing Task __1__ and save the plots from Tasks __3.3__, __4.4__, and __5.3__.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "555eb3fb",
      "metadata": {},
      "source": [
        "# Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b5ff87",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch utilizing dev cuda:0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# The following line is used to deactivate the use of the GPU.\n",
        "# If you want to utilize the GPU, just comment the codeline and restart the Kernel.\n",
        "# The print command in the end of the block states whether CPU or GPU are utilized.\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "from pyDOE import *\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "from tqdm import trange\n",
        "from torch.autograd import grad\n",
        "from utils.data_generator import Schrodinger_Boundary, Schrodinger, Schrodinger_Initial, SharedData\n",
        "from utils.Schrodinger_Animator import AnimationCreator\n",
        "from utils.tools import SolutionVisualizer, logarithmic_sampling, get_prediction, visualize_training, visualize_imported_data\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch utilizing dev\",device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465f7121",
      "metadata": {},
      "source": [
        "# Data Import\n",
        "\n",
        "The data we are working with describes the initial state of the quantum harmonic oscillator.\n",
        "It is generated using four imported classes.  \n",
        "- The `shared_data` class contains all relevant information about the system, such as the length of the time interval `period` and order `n` of the wavefunction.  \n",
        "\n",
        "- To create data , we use three classes named after their purpose:\n",
        "    1. The `Schrodinger_Boundary` class provides collocation points at $x\\pm 5$. The corresponding loss function is evaluated to induce symmetry to the system.\n",
        "    2. The `Schrodinger_Initial` class provides labeled data at $t=0$. This data is used to infer the initial condition via the associated loss function into the system.\n",
        "    3. The `Schrodinger` class provides collocation in the $x,t$-plane, where the physics loss function is computed.\n",
        "\n",
        "__Tasks__:  \n",
        "Run the following two cells and become familiar with the provided data sets and take notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9381d89",
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_data = SharedData(n=0)\n",
        "boundary = Schrodinger_Boundary(shared_data)\n",
        "initial = Schrodinger_Initial(shared_data)\n",
        "schrodinger = Schrodinger(shared_data)\n",
        "period = shared_data.period\n",
        "print(\"Period:\",period/math.pi, \"pi\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02c2a25a",
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_imported_data(boundary, initial, schrodinger, shared_data, save_svg=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4fb0b60",
      "metadata": {},
      "source": [
        "# Data preperation\n",
        "\n",
        "To prepare for further processing, the datasets mentioned above must be split into two partitions to create a training and testing dataset.\n",
        "\n",
        "__Task:__  \n",
        "Review the following function and takes notes. Pay particular attention to:\n",
        "- its inputs and outputs.\n",
        "- The entries of keys and their values (why are some values missing?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdffed33",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data(\n",
        "        boundary_vals, \n",
        "        initial_vals, \n",
        "        schrodinger_vals,\n",
        "        num_col_train = 20000,\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Create training and test data for training procedure.\n",
        "\n",
        "    This function generates training and test datasets using a subset\n",
        "    of the boundary values, initial values and the schrodinger values.\n",
        "    Therefore the following steps need to be done:\n",
        "        1. Data Point Selection\n",
        "        2. Training Data Creation\n",
        "        3. Testing Data Creation\n",
        "        4. Unpacking Data\n",
        "        5. Gradient Data \n",
        "        6. Dataset Creation\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    boundary_vals : Schrodinger_Boundary \n",
        "        Object containing boundary values.\n",
        "    initial_vals : Schrodinger_Initial\n",
        "        Object containing initial values.\n",
        "    schrodinger_vals : Schrodinger\n",
        "        Object containing schrodinger values.\n",
        "    num_col_train : int\n",
        "        Number of collocation points.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    train_ds : Dict\n",
        "        A dictionary containing \"boundary\", \"initial\" and \"schrodinger\" entries for training data.\n",
        "    test_ds : Dict\n",
        "        A dictionary containing \"boundary\", \"initial\" and \"schrodinger\" entries for testing data.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Step 1: Data Point Selection\n",
        "    num_col_tot = 20000\n",
        "    all_idx = torch.arange(0, num_col_tot, dtype=torch.int)\n",
        "    idx_col_train = torch.linspace(0, num_col_tot-1, num_col_train, dtype=torch.int)\n",
        "    mask = ~torch.isin(all_idx, idx_col_train)\n",
        "    idx_col_test = all_idx[mask]\n",
        "    \n",
        "    # Step 2: Training Data Creation\n",
        "    schrodinger_train = schrodinger_vals[idx_col_train]\n",
        "    schrodinger_train_x = schrodinger_train[0].clone().detach()\n",
        "    schrodinger_train_t = schrodinger_train[1].clone().detach()\n",
        "    \n",
        "    # Step 3: Testing Data Creation\n",
        "    schrodinger_test = schrodinger_vals[idx_col_test]\n",
        "    schrodinger_test_x = schrodinger_test[0].clone().detach()\n",
        "    schrodinger_test_t = schrodinger_test[1].clone().detach()\n",
        "\n",
        "    # Step 4: Unpacking Data\n",
        "    boundary_input_x = boundary_vals.getall()[0].clone().detach()\n",
        "    boundary_input_t = boundary_vals.getall()[1].clone().detach()\n",
        "    initial_input_x = initial_vals.getall()[0].clone().detach()\n",
        "    initial_input_t = initial_vals.getall()[1].clone().detach()\n",
        "    initial_target = initial_vals.getall()[2].clone().detach()\n",
        "\n",
        "    # Step 5: Gradient Data \n",
        "    boundary_input_x.requires_grad = True\n",
        "    boundary_input_t.requires_grad = True\n",
        "    initial_input_x.requires_grad = True\n",
        "    initial_input_t.requires_grad = True\n",
        "    initial_target.requires_grad = True\n",
        "\n",
        "    schrodinger_train_x.requires_grad = True\n",
        "    schrodinger_train_t.requires_grad = True\n",
        "    schrodinger_test_x.requires_grad = True  \n",
        "    schrodinger_test_t.requires_grad = True\n",
        "\n",
        "    boundary_inputs = [boundary_input_x, boundary_input_t]\n",
        "    initial_inputs = [initial_input_x, initial_input_t]\n",
        "    schrodinger_train = [schrodinger_train_x, schrodinger_train_t]\n",
        "    schrodinger_test = [schrodinger_test_x, schrodinger_test_t]\n",
        "    \n",
        "    # Step 6: Dataset Creation\n",
        "    train_ds = {\"boundary\": {\"inputs\": boundary_inputs, \"targets\": []}, \n",
        "                \"initial\": {\"inputs\": initial_inputs, \"targets\": initial_target},\n",
        "                 \"schrodinger\": {\"inputs\": schrodinger_train, \"targets\": []}}\n",
        "    test_ds = {\"boundary\": {\"inputs\": boundary_inputs, \"targets\": []}, \n",
        "                \"initial\": {\"inputs\": initial_inputs, \"targets\": initial_target},\n",
        "                 \"schrodinger\": {\"inputs\": schrodinger_test, \"targets\": []}}\n",
        "\n",
        "    # Return the created datasets\n",
        "    return train_ds, test_ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4357fac",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds, test_ds = prepare_data(boundary, initial, schrodinger, num_col_train=15000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c395edc",
      "metadata": {},
      "source": [
        "# Create PINN model\n",
        "\n",
        "__Task:__  \n",
        "Review the following class and take notes.  \n",
        "Pay particular attention to:\n",
        "- The number and width of layers.\n",
        "- the forward pass.\n",
        "- What input and output nodes the model posesses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d02ced86",
      "metadata": {},
      "outputs": [],
      "source": [
        "class PINN(nn.Module):\n",
        "    \"\"\"\n",
        "    Physics-Informed Neural Network (PINN) Class\n",
        "    \n",
        "    This class as a subclass of torch.nn.Module defines the architecture of the PINN model. \n",
        "    It is designed to use differential equations while incorporating physics-based constraints.\n",
        "    The process consists of the following steps:\n",
        "    \n",
        "    Step 1: Model Initialization\n",
        "        - Initialize the PINN model as a subclass of nn.Module.\n",
        "\n",
        "    Step 2: Constructor Definition\n",
        "        - Build a constructor to configure the model's architecture.\n",
        "        - Utilize the nn.Linear class from the PyTorch library for defining layers and connections.\n",
        "        - Initialize the weights of the layers using the Xavier uniform initializer.\n",
        "\n",
        "    Step 3: Forward Pass Mechanism\n",
        "        - Define the forward pass mechanism for the model, where input data flows through the layers\n",
        "          to produce predicted outputs.\n",
        "       \n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Constructor for the PINN class.\n",
        "        \n",
        "        Initializes the layers of the neural network:\n",
        "        - Input layer fc1 taking a tensor with time and space data.\n",
        "        - Four hidden fully connected layers fc2-fc5 with 50 neurons.\n",
        "        - Output layer h_real for predicting the real part.\n",
        "        - Output layer h_imag for predicting the imaginary part.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        None\n",
        "            \n",
        "        Attributes\n",
        "        ----------\n",
        "        fc1 : nn.Linear\n",
        "            First fully connected layer.\n",
        "        fc2 : nn.Linear\n",
        "            Second fully connected layer.\n",
        "        fc3 : nn.Linear\n",
        "            Third fully connected layer.\n",
        "        fc4 : nn.Linear\n",
        "            Fourth fully connected layer.\n",
        "        fc5 : nn.Linear\n",
        "            Fifth fully connected layer.\n",
        "        h_real : nn.Linear\n",
        "            Output layer for x-coordinate prediction.\n",
        "        h_imag : nn.Linear\n",
        "            Output layer for y-coordinate prediction.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        \n",
        "        \"\"\"\n",
        "        super(PINN, self).__init__()\n",
        "        layer_width = 50\n",
        "        # Step 2: Constructor Definition\n",
        "        torch.manual_seed(42)  # Set seed for reproducibility\n",
        "        self.fc1 = nn.Linear(2,layer_width).to(device)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        self.fc2 = nn.Linear(layer_width,layer_width).to(device)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        self.fc3 = nn.Linear(layer_width,layer_width).to(device)\n",
        "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
        "        self.fc4 = nn.Linear(layer_width,layer_width).to(device)\n",
        "        torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
        "        self.fc5 = nn.Linear(layer_width,layer_width).to(device)\n",
        "        torch.nn.init.xavier_uniform_(self.fc5.weight)\n",
        "        self.h_real = nn.Linear(layer_width,1).to(device)\n",
        "        torch.nn.init.xavier_uniform_(self.h_real.weight)\n",
        "        self.h_imag = nn.Linear(layer_width,1).to(device)\n",
        "        torch.nn.init.xavier_uniform_(self.h_imag.weight)\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform a forward pass through the PINN model.\n",
        "        \n",
        "        This method defines the forward pass mechanism of the PINN model, where\n",
        "        the input data X is processed through the layers to produce predicted\n",
        "        outputs for both real part of the solution (h_real) \n",
        "        and imaginary part of the solution (h_imag).\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        t : torch.Tensor\n",
        "            Input data tensor.\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        h_real : torch.Tensor\n",
        "            Predicted real part of the solution.\n",
        "        h_imag : torch.Tensor\n",
        "            Predicted imaginary part of the solution.\n",
        "        \"\"\"\n",
        "\n",
        "        # Step 1: Forward Pass Mechanism\n",
        "        x = torch.tanh(self.fc1(x))   \n",
        "        x = torch.tanh(self.fc2(x))  \n",
        "        x = torch.tanh(self.fc3(x))  \n",
        "        x = torch.tanh(self.fc4(x))  \n",
        "        x = torch.tanh(self.fc5(x))     \n",
        "\n",
        "        # Step 2: Produce predicted real and imaginary solution using output layers and return them. \n",
        "        h_real = self.h_real(x)\n",
        "        h_imag = self.h_imag(x)\n",
        "\n",
        "        return h_real, h_imag"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4719255b",
      "metadata": {},
      "source": [
        "# Boundary loss\n",
        "To solve the time-dependent Schrödinger Equation, we need to consider the symmetry of the time evolution. This requires adding boundary points and defining a boundary loss that constrain the symmetry.  \n",
        "Boundary Conditions:\n",
        "\n",
        "*   $h(5,t)=h(-5,t) \\quad \\Leftrightarrow\\quad  h(5,t)-h(-5,t)=0$ \n",
        "\n",
        "*   $\\frac{\\partial }{\\partial x}h(5,t)=-\\frac{\\partial }{\\partial x}h(-5,t) \\quad\\Leftrightarrow\\quad \\frac{\\partial }{\\partial x}h(5,t)+\\frac{\\partial }{\\partial x}h(-5,t)=0$\n",
        "\n",
        "Task:\n",
        "\n",
        "Define the `compute_boundary_loss` function by following the steps stated in the docstring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_boundary_loss(model : nn.Module, dataset : dict):\n",
        "    \"\"\"\n",
        "    Define the boundary loss, representing one part of the physics-informed loss for the PINN model.\n",
        "    \n",
        "    This function calculates the loss used to incorporate the boundary conditions\n",
        "    into the PINN. The following steps are involved:\n",
        "    \n",
        "    Step 1: Data Preparation\n",
        "        - Get the boundary inputs (x_bound and t_bound) from the dataset.\n",
        "\n",
        "    Step 2: Model Prediction\n",
        "        - Concatenate the two input tensors along axis 1.\n",
        "        - Using the concatenated tensors, predict the real and imaginary values with the neural network model.\n",
        "\n",
        "    Step 3: Gradient Computation\n",
        "        - Compute the first gradients 'hp_r_x', 'hp_i_x', 'hn_r_x', and 'hn_i_x' \n",
        "          with respect to the 'x' input tensor using the 'torch.autograd.grad' method.\n",
        "\n",
        "    Step 4: Difference Calculation\n",
        "        - Calculate the difference between 'hp' (h at x=5) and 'hn' (h at x=-5) for real and imaginary parts.\n",
        "\n",
        "    Step 5: Derivative Sum Calculation\n",
        "        - Calculate the Sum of 'hp_x' and 'hn_x' for real and imaginary parts.\n",
        "\n",
        "    Step 6: Residual Definition\n",
        "        - Define 'h_err' and 'h_x_err' by adding the squared difference/sum previously calculated.\n",
        "\n",
        "    Step 7: Loss Calculation\n",
        "        - Compute the mean squared error loss for 'h_err' and 'h_x_err' using the 'nn.MSELoss' class.\n",
        "        - as a target serves a tensor containing zeros. It can be produced using 'torch.zeros_like'\n",
        "        - Return the combined physics-informed loss as the sum of 'loss_h' and 'loss_h_x'.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The physics-informed neural network model.\n",
        "    dataset : dict\n",
        "        A dictionary containing \"boundary\" entries.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The combined (h and h_x) physics-informed loss.\n",
        "    \"\"\"\n",
        "    # Step 1: Data Preparation\n",
        "    x_bound, t_bound = dataset[\"boundary\"][\"inputs\"]\n",
        "\n",
        "    \n",
        "    # Step 2: Model Prediction\n",
        "    hp_r, hp_i = model(torch.cat((x_bound, t_bound),1))\n",
        "    hn_r, hn_i = model(torch.cat((-x_bound, t_bound),1))\n",
        "\n",
        "    \n",
        "    # Step 3: Gradient Computation\n",
        "    hp_r_x = grad(outputs=hp_r, inputs=x_bound, grad_outputs=torch.ones_like(hp_r), create_graph=True)[0]\n",
        "    # hp_i_x = \n",
        "\n",
        "    hn_r_x = grad(outputs=hn_r, inputs=x_bound, grad_outputs=torch.ones_like(hn_r), create_graph=True)[0]\n",
        "    # hn_i_x = \n",
        "\n",
        "    \n",
        "    # Step 4: Difference Calculation\n",
        "\n",
        "\n",
        "    # Step 5: Derivative Sum Calculation\n",
        "\n",
        "\n",
        "    # Step 6: Residual Definition\n",
        "\n",
        "\n",
        "    # Step 7: Loss Calculation\n",
        "\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fd5033a",
      "metadata": {},
      "source": [
        "__Checkpoint:__  \n",
        "In the next cell, you will test your defined loss function on a generated dataset and an instance of the PINN.\n",
        "If implemented correctly, it will always produce the same value, regardless of the randomly generated data points and network parameters.\n",
        "This is due to the predefined seed value used for parameter and data initialization, which ensures consistent distribution every time.  \n",
        "\n",
        "If you run the following cell and you don't produce an error, it means that your `compute_boundary_loss` function has been implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1274c17b",
      "metadata": {},
      "outputs": [],
      "source": [
        "Dummy_NN = PINN()\n",
        "\n",
        "dummy_train_ds, dummy_test_ds = prepare_data(boundary, initial, schrodinger, num_col_train=20000)\n",
        "\n",
        "dummy_boundry_loss = compute_boundary_loss(Dummy_NN, dummy_train_ds)\n",
        "\n",
        "assert round(dummy_boundry_loss.item(), 5) == 0.07453, f'Your boundary loss of {round(dummy_boundry_loss.item(), 5)} is not correct!'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83b55a53",
      "metadata": {},
      "source": [
        "# Initial loss\n",
        "\n",
        "This part is used, to implement the initial state $\\psi(x,0)$ of the system, as visualized above.  \n",
        "__Task:__  \n",
        "Define the `compute_initial_loss` function by following the steps stated in the docstring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ddc4b6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_initial_loss(model : nn.Module, dataset: dict):\n",
        "    \"\"\"\n",
        "    Calculate the loss associated with satisfying the initial conditions for the PINN model.\n",
        "\n",
        "    This function computes the loss that measures how well the initial conditions are met by the PINN. \n",
        "    The dataset containes information about the initial condition.\n",
        "    The following steps are involved:\n",
        "\n",
        "    Step 1: Data Preparation\n",
        "        - Extract 'x_0', 't_0' and 'psi_0' from the training dataset.\n",
        "\n",
        "    Step 2: Model Prediction\n",
        "        - Concatenate the two input tensors along axis 1.\n",
        "        - Use the neural network model to predict the real and imaginary values at (x_0, t_0).\n",
        "\n",
        "    Step 3: Concatenation\n",
        "        - Concatenate the real and imaginary parts of the predicted values along axis 1.\n",
        "\n",
        "    Step 4: Loss Calculation\n",
        "        - Calculate and return the mean squared error loss between 'psi_0' and the concatenated values 'h'.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The physics-informed neural network model.\n",
        "    dataset : dict\n",
        "        A dictionary that includes \"initial\" entries with \"x_0,\" \"t_0,\" and \"psi_0.\"\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The loss quantifying how well the initial conditions are satisfied.\n",
        "    \"\"\"\n",
        "    # Step 1: Data Preparation\n",
        "\n",
        "    # Step 2: Model Prediction\n",
        "\n",
        "    # Step 3: Concatenation\n",
        "    \n",
        "    # Step 4: Loss Calculation\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede7b81a",
      "metadata": {},
      "source": [
        "__Checkpoint:__  \n",
        "If you run the following cell and you don't produce an error, it means that your ``compute_initial_loss`` function has been implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18cfa142",
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_initial_loss = compute_initial_loss(Dummy_NN, dummy_train_ds)\n",
        "\n",
        "assert round(dummy_initial_loss.item(), 5) == 0.04446, f'Your initial loss {round(dummy_initial_loss.item(), 5)} is not correct!'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "970a4ed3",
      "metadata": {},
      "source": [
        "# Physics-informed Loss\n",
        "\n",
        "The time dependant Schrodinger Equation describes the time evolution of the quantum mechanic harmonic oscillator:\n",
        "\n",
        "$i\\hbar\\frac{\\partial}{\\partial t}\\psi(x,t)=\\hat{H} \\psi(x,t) $  \n",
        "\n",
        "After reordering and using the Hamiltonian of the quantum harmonic oscillator, we obtain:\n",
        "\n",
        "$\\left(i\\hbar\\frac{\\partial}{\\partial t}+\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial x^2}-\\frac{m \\omega^2}{2}x^2\\right) \\psi(x,t)=0$ \n",
        "\n",
        "However, this equation cannot be directly applied to the `compute_physics_informed_loss` function in its current form.  \n",
        "This is because the model predicts separate solutions for the real and imaginary parts, labeled as $\\psi_r(x,t) $ and $ \\psi_i(x,t)$ respectively, instead of a single solution $\\psi(x,t)$.  \n",
        "To implement the equation, first divide it into real and imaginary parts.  \n",
        "Complete the following tasks:\n",
        "\n",
        "1. Replace $\\psi(x,t)$ with $\\psi_r(x,t) + i \\psi_i(x,t)$ and insert it into the equation.\n",
        "\n",
        "2. Split the left side of the equation into its real and imaginary parts.\n",
        "\n",
        "3. Follow the step-by-step explanation to define the `compute_physics_informed_loss` function and use the  \n",
        "   results from Task 2 to define the residuals `f_r` and `f_i`.  \n",
        "   __hint__: Set $ m =1 $, $\\hbar =1$ and $\\omega =1$  \n",
        "\n",
        "Comment: The boolean value `potential_scaling` is used in the final task, so ignore it for now.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_physics_informed_loss(model : nn.Module, dataset: dict, potential_scaling:bool = False):\n",
        "    \"\"\"\n",
        "    Calculate the loss for the Schrödinger equation condition in the PINN model.\n",
        "\n",
        "    This function computes the loss that measures how well the Schrödinger equation condition\n",
        "    is satisfied by the PINN. The following steps are involved:\n",
        "\n",
        "    Step 1: Data Preparation\n",
        "        - Get the schrodinger inputs (x_schr and t_schr) from the dataset.\n",
        "\n",
        "    Step 2: Model Prediction\n",
        "        - Concatenate the two input tensors along axis 1.\n",
        "        - Use the neural network model to predict the real and imaginary values.\n",
        "\n",
        "    Step 3: Derivative Computation\n",
        "        - Compute the first derivatives with respect to 't_schr' and the second derivatives with respect to 'x_schr' \n",
        "          for both the real and the imaginary part of the solution.\n",
        "\n",
        "    Step 4: Residuals Definition\n",
        "        - Define residuals 'f_r' and 'f_i' that contain the Schrödinger equation condition for the real and imaginary parts.\n",
        "\n",
        "    Step 5: Residual Calculation\n",
        "        - Define a residual 'f' by computing the Euclidean norm from 'f_r' and 'f_i.'\n",
        "\n",
        "    Step 6: Loss Calculation\n",
        "        - Calculate and return the mean squared error loss between 'f' and zeros.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The physics-informed neural network model.\n",
        "    dataset : dict\n",
        "        A dictionary containing \"schrodinger\" entries.\n",
        "    potential_scaling : bool\n",
        "        Whether the potential scaling is set to True of false.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The loss quantifying how well the Schrödinger equation condition is satisfied.\n",
        "    \"\"\"\n",
        "    # Step 1: Data Preparation\n",
        "\n",
        "    # Step 2: Model Prediction\n",
        "\n",
        "    # Step 3: Derivative Computation\n",
        "\n",
        "    # Step 4: Residuals Definition\n",
        "\n",
        "    # Step 5: Residual Calculation\n",
        "\n",
        "    # Step 6: Loss Calculation\n",
        "    \n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d065c1e",
      "metadata": {},
      "source": [
        "__Checkpoint:__  \n",
        "If you run the following cell and you don't produce an error, it means that your ``compute_physics_informed_loss`` function has been implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a614b01",
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_physics_loss = compute_physics_informed_loss(Dummy_NN, dummy_train_ds, potential_scaling=False)\n",
        "\n",
        "assert round(dummy_physics_loss.item(), 5) == 5.61577, f'The physics loss {round(dummy_physics_loss.item(), 5)} is not correct!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Total loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_total_loss(model : nn.Module, dataset: dict, potential_scaling:bool):\n",
        "    \"\"\"\n",
        "    Define the total loss for the physics-informed neural network.\n",
        "\n",
        "    This function computes the total loss for the PINN model by combining three\n",
        "    different components:  boundary, inital and physics-informed loss.\n",
        "    The following steps are involved:\n",
        "\n",
        "    Step 1: Loss Calculation\n",
        "        - Determine the boundary, inital and physics loss using the corresponding functions.\n",
        "\n",
        "    Step 2: Total Loss Combination\n",
        "        - Return the combined total loss as the sum of the three losses.\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The physics-informed neural network model.\n",
        "    dataset : dict\n",
        "        A dictionary containing \"inputs\", \"targets_x\", \"targets_y\", and \"t_col\" entries.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The combined total loss considering data and physics constraints.\n",
        "    \"\"\"\n",
        "    # Step 1: Loss Calculation\n",
        "    initial_loss = compute_initial_loss(model, dataset)\n",
        "    boundary_loss = compute_boundary_loss(model, dataset)\n",
        "    physics_loss = compute_physics_informed_loss(model, dataset, potential_scaling)\n",
        "\n",
        "    # Step 2: Total Loss Combination\n",
        "    total_loss = initial_loss + physics_loss + boundary_loss\n",
        "\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "245a6957",
      "metadata": {},
      "source": [
        "__Checkpoint:__  \n",
        "If you run the following cell and you don't produce an error, it means that your ``compute_total_loss`` function has been implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ad4982",
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_total_loss = compute_total_loss(Dummy_NN, dummy_train_ds, potential_scaling=False)\n",
        "\n",
        "assert round(dummy_total_loss.item(), 5) == 5.73475, f'The total loss {round(dummy_total_loss.item(), 5)} is not correct!'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee38f439",
      "metadata": {},
      "source": [
        "# Execution function\n",
        "\n",
        "__Task:__  \n",
        "Inspect the execute function and take notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute(\n",
        "        model : nn.Module,\n",
        "        train_ds: dict,\n",
        "        test_ds: dict,\n",
        "        lr = 0.00025, \n",
        "        num_epochs = 2500,\n",
        "        num_batches = 25,\n",
        "        potential_scaling = False,\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Execute the training procedure for a physics-informed neural network model.\n",
        "\n",
        "    This function trains the model using specified hyperparameters and returns relevant data.\n",
        "\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The neural network model to be trained and evaluated.\n",
        "    train_ds : dict\n",
        "        A dictionary containing initial, boundary and schrodinger training data.\n",
        "    test_ds : dict\n",
        "        A dictionary containing initial, boundary and schrodinger testing data.\n",
        "    lr : float, optional\n",
        "        Learning rate for the optimizer. Default is 0.00025.\n",
        "    num_epochs : int, optional\n",
        "        Number of epochs to train the model. Default is 2000.\n",
        "    num_batches : int, optional\n",
        "        Number of batches to split the training data into. Default is 25.\n",
        "    potential_scaling : bool, optional\n",
        "        Whether to use the potential scaling or not. Default is False.\n",
        "\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    train_loss_evolution : list\n",
        "        A list containing train loss values during training.\n",
        "    test_loss_evolution : list\n",
        "        A list containing test loss values during training\n",
        "    predictions_list : list\n",
        "        A list containing the model predictions at logarithmically sampled epochs.\n",
        "    \"\"\"   \n",
        "\n",
        "    # Step 1: Optimizer Initialization\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr,)  # Include weight_decay in the optimizer\n",
        "\n",
        "    # Step 2: Lists Initialization\n",
        "    train_loss_evolution = []\n",
        "    test_loss_evolution = []\n",
        "    predictions_list = []\n",
        "\n",
        "    # Define Loading Bar\n",
        "    loading_bar = trange(1, num_epochs + 1)\n",
        "\n",
        "    # Step 3: Training Loop Setup\n",
        "    for epoch in loading_bar:\n",
        "        # Step 4: Epoch Loss Tracking\n",
        "        train_loss = compute_total_loss(model, train_ds, potential_scaling)\n",
        "        test_loss = compute_total_loss(model, test_ds, potential_scaling)\n",
        "        test_loss_evolution.append(float(test_loss))\n",
        "        train_loss_evolution.append(float(train_loss))\n",
        "\n",
        "        # Prediction tracking\n",
        "        if epoch in logarithmic_sampling(num_epochs):\n",
        "            h_hat = get_prediction(model, period=shared_data.period, device=device)\n",
        "            predictions_list.append(h_hat)\n",
        "\n",
        "        # Step 5: Permutation of Training Data\n",
        "        permutations = torch.randperm(min(train_ds[\"schrodinger\"][\"inputs\"][0].shape[0], \n",
        "                                        train_ds[\"initial\"][\"inputs\"][0].shape[0], \n",
        "                                        train_ds[\"boundary\"][\"inputs\"][0].shape[0]))\n",
        "        permutations = torch.tensor_split(permutations, num_batches)\n",
        "\n",
        "        # Step 6: Nested Batch Training Loop Setup\n",
        "        for i in range(len(permutations)):\n",
        "            # Step 7: Data Preparation\n",
        "            train_batch_ds = {\"boundary\": {\"inputs\": [], \"targets\": []}, \n",
        "                            \"initial\": {\"inputs\": [], \"targets\": []},\n",
        "                            \"schrodinger\": {\"inputs\": [], \"targets\": []}}\n",
        "\n",
        "            perm_init_x = torch.tensor_split(train_ds[\"initial\"][\"inputs\"][0], num_batches)\n",
        "            perm_init_t = torch.tensor_split(train_ds[\"initial\"][\"inputs\"][1], num_batches)\n",
        "            train_batch_ds[\"initial\"][\"inputs\"] = [perm_init_x[i], perm_init_t[i]]\n",
        "            \n",
        "            perm_init_psi = torch.tensor_split(train_ds[\"initial\"][\"targets\"], num_batches)\n",
        "            train_batch_ds[\"initial\"][\"targets\"] = perm_init_psi[i]\n",
        "        \n",
        "            perm_bound_x = torch.tensor_split(train_ds[\"boundary\"][\"inputs\"][0], num_batches)\n",
        "            perm_bound_t = torch.tensor_split(train_ds[\"boundary\"][\"inputs\"][1], num_batches)\n",
        "            train_batch_ds[\"boundary\"][\"inputs\"] = [perm_bound_x[i], perm_bound_t[i]]\n",
        "        \n",
        "            perm_schrodinger_x = torch.tensor_split(train_ds[\"schrodinger\"][\"inputs\"][0], num_batches)\n",
        "            perm_schrodinger_t = torch.tensor_split(train_ds[\"schrodinger\"][\"inputs\"][1], num_batches)\n",
        "            train_batch_ds[\"schrodinger\"][\"inputs\"] = [perm_schrodinger_x[i], perm_schrodinger_t[i]]\n",
        "\n",
        "        \n",
        "            # Step 8: Batch Training\n",
        "            optimizer.zero_grad()\n",
        "            train_loss = compute_total_loss(model, train_batch_ds, potential_scaling)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Step 9: Print Progress\n",
        "        loading_bar.set_description(f\"Epoch: {epoch}\")\n",
        "        loading_bar.set_postfix({\"Test Loss\": test_loss.item(), \"Train Loss\": train_loss.item()})\n",
        "        \n",
        "\n",
        "    # Step 10: Data Return\n",
        "    return train_loss_evolution, test_loss_evolution, predictions_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3681e019",
      "metadata": {},
      "source": [
        "# Execution task: Verification\n",
        "__Task:__  \n",
        "1. Initialize the model by calling the PINN class created earlier.\n",
        "2. Generate training and test datasets by calling the 'prepare_data' function.\n",
        "    - Use __20000 collocation training points__ for data generation.\n",
        "3. Execute the training for the following set of (hyper)parameters:        \n",
        "    - Train over  $n_\\text{epochs} =2500$ __epochs__.\n",
        "    - Set the number of __mini-batches__ to $n_\\text{batches}=25$\n",
        "    - Set `potential_scaling` to __False__\n",
        "\n",
        "The training requires some time. Take a coffee break and do some push ups.  \n",
        "After completion, check the loss evolution by running the next cell.\n",
        "A loss around $\\mathcal{L}=10^{-4}$ indicates good performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "102475fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Initialize the model by calling the PINN class created earlier.\n",
        "model = PINN()\n",
        "\n",
        "# Step 2: Generate training and test datasets by calling the 'prepare_data' function.\n",
        "train_ds, test_ds = prepare_data(boundary, \n",
        "        initial, \n",
        "        schrodinger,\n",
        "        num_col_train=20000,\n",
        "        )\n",
        "# Step 3: Execute the training and testing of the model.\n",
        "train_loss_evolution, test_loss_evolution, predictions_list = execute(\n",
        "    model,\n",
        "    test_ds=test_ds,\n",
        "    train_ds=train_ds,\n",
        "    num_epochs=2500,\n",
        "    num_batches=25,\n",
        "    potential_scaling=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5e7e6bc",
      "metadata": {},
      "source": [
        "__Saving the trained model__:  \n",
        "By running the following cell, the trained model and its adjusted parameters will be saved in a file named `trained_model.pth`. \n",
        "If you need to restart your kernel for any reason, you can load the trained model by running the subsequent cell.\n",
        "Ensure that you run the import cells and the cell where the PINN class is defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4808653f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model, \"trained_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3db07b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now you can load the model\n",
        "loaded_model = torch.load(\"trained_model.pth\", weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df53ae4",
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_training(train_loss_evolution, test_loss_evolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02340670",
      "metadata": {},
      "source": [
        "# Result animation\n",
        "\n",
        "After training the model, it is time to verify that it has learned the time evolution of the initial state.  \n",
        "\n",
        "__Tasks:__\n",
        "- To produce and export four animations as mp4-files, as well as the last frame of the animations as svg-files, run the following cell.\n",
        "- Investigate the animations and determine their meaning. their meaning and present your findings, along with the animations, to your tutor for approval before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4bf2147",
      "metadata": {},
      "outputs": [],
      "source": [
        "animator = AnimationCreator(model, period, predictions_list=predictions_list, device=device)\n",
        "animator.create_meshgrid()\n",
        "animator.compute_solution()\n",
        "animator.create_train_evolution_real_animation()\n",
        "animator.create_train_evolution_imag_animation()\n",
        "animator.create_cross_section_animation()\n",
        "animator.create_complex_plot_animation()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f0cd36",
      "metadata": {},
      "source": [
        "# Execution task 4: Energy Eigenvalues\n",
        "The PINN model can now predict the temporal evolution of the wave function over a period.  \n",
        "We will now test whether the energy of the corresponding predicted wave function is consistent with the theory.  \n",
        "To accomplish this, we begin with the eigenvalue equation of the Hamiltonian.  <br>\n",
        "\n",
        "$\\hat{H}| \\psi_n \\rangle = E_n  | \\psi_n \\rangle$  \n",
        "\n",
        "We multiply both sides with the Bra vector $\\langle \\psi_n |$ to it:  \n",
        "\n",
        "$\\langle \\psi_n| \\hat{H} | \\psi_n \\rangle = E_n \\langle \\psi_n | \\psi_n \\rangle$  \n",
        "\n",
        "We can now evaluate the integral in position space and solve for the energy eigenvalue.  \n",
        "Let's also denote both integrals with $I_1$ and $I_2$, so that we can treat them each at a time:\n",
        "\n",
        "$E_n = \\underbrace{\\left(\\int_{-\\infty}^{\\infty} \\psi_n^*(x,t)\\cdot \\hat{H}\\cdot \\psi_n(x,t) \\,dx\\right)}_{I_1}/\\underbrace{\\left(\\int_{-\\infty}^{\\infty}\\psi_n^*(x,t)\\cdot \\psi_n(x,t)\\,dx\\right)}_{I_2}$\n",
        "\n",
        "Writing out the Hamiltonian in integral $I_1$ we obtain:\n",
        "\n",
        "$I_1=\\int_{-\\infty}^{\\infty} \\psi_n^*(x,t)\\cdot\\left(\\frac{\\hat{p}^2}{2m}+\\frac{m \\omega^2}{2}x^2\\right)\\cdot \\psi_n(x,t) \\,dx$\n",
        "\n",
        "The integral can be divided into two parts, named $I_{1a}$ and $I_{1b}$.\n",
        "\n",
        "$I_1=\\underbrace{\\frac{1}{2m}\\int_{-\\infty}^{\\infty} \\psi_n^*(x,t)\\cdot\\hat{p}^2\\psi_n(x,t)\\,dx}_{I_{1a}} + \\underbrace{\\frac{m \\omega^2}{2}\\int_{-\\infty}^{\\infty} \\psi_n^*(x,t)\\cdot\\psi_n(x,t)\\cdot x^2 \\,dx}_{I_{1b}}$\n",
        "\n",
        "Integral $I_{1b}$ can be further simplified, since $\\psi_n^*(x,t)\\cdot\\psi_n(x,t)=|\\psi_n(x,t)|^2$:\n",
        "\n",
        "$I_{1b}=\\frac{m \\omega^2}{2}\\int_{-\\infty}^{\\infty} |\\psi_n(x,t)|^2\\cdot x^2 \\,dx$\n",
        "\n",
        "After reordering and combining everything, we end up with:\n",
        "\n",
        "$E_n = \\frac{\\overbrace{\\frac{m \\omega^2}{2}\\int_{-\\infty}^{\\infty} |\\psi_n(x,t)|^2\\cdot x^2 \\,dx}^{I_{1b}} + \\overbrace{\\frac{1}{2m}\\int_{-\\infty}^{\\infty} \\psi_n^*(x,t)\\cdot\\hat{p}^2\\psi_n(x,t) \\,dx}^{I_{1a}} }{\\underbrace{\\int_{-\\infty}^{\\infty}|\\psi_n(x,t)|^2,dx}_{I_2}}$\n",
        "___\n",
        "4. Energy Eigenvalues:  \n",
        "\n",
        "   However, we cannot directly apply this equation to our model in this form.  \n",
        "   Because, the model prediction is limited to the $[-5,5]$ in space.  \n",
        "   Additionally, the model provides separate solutions for the real and imaginary parts of $\\psi$, rather than a single solution.  \n",
        "   Therefore complete the following Tasks: \n",
        "   <br><br>\n",
        "\n",
        "   1. Split up the right side of the last equation, into a real and an imaginary part.  \n",
        "      __Hint__: Integral $I_{1b}$ and $I_2$ are already purely real, so don't waste your time on them.\n",
        "   <br><br>\n",
        "\n",
        "   2. Implement a function called `compute_momentum_squared`  \n",
        "      that returns the negative second derivative of the real and imaginary parts of the model's prediction.\n",
        "      <br><br>\n",
        "\n",
        "   3. Implement a function called `compute_energy_eigenvalue`  \n",
        "      that returns a list containing a number of `n_time_steps` Energy values between `t=0` and `t=period`.  \n",
        "      __hint__: Set $ m =1 $, $\\hbar =1$ and $\\omega =1$  \n",
        "      __hint__: To calculate an integral, use the torch command `torch.trapz`.\n",
        "      <br><br>\n",
        "\n",
        "   4. Plot the real and imaginary parts of the energy eigenvalue over time  \n",
        "      and explain the result in the evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370cdccd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_momentum_squared(model : nn.Module, x, t):\n",
        "    \"\"\"\n",
        "    Calculate the momentum squared of the wavefunction.\n",
        "\n",
        "    This function computes the momentum squared of the wavefunction by using the\n",
        "    neural network model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The physics-informed neural network model.\n",
        "    x : torch.Tensor\n",
        "        The x values.\n",
        "    t : torch.Tensor\n",
        "        The t values.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    p2_h_r : torch.Tensor\n",
        "        The momentum squared of the real part wavefunction.\n",
        "    p2_h_i : torch.Tensor\n",
        "        The momentum squared of the imaginary part wavefunction.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0271f08",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_energy_eigenvalue(model : nn.Module, n_time_steps=100):\n",
        "    \"\"\"\n",
        "    This function computes the energy eigenvalues of the Schrödinger equation.\n",
        "\n",
        "    parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The physics-informed neural network model.\n",
        "    n_time_steps : int\n",
        "        The number of time steps.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    energy_eigenvalues_real : list\n",
        "        The real part of the energy eigenvalues.\n",
        "    energy_eigenvalues_imag : list\n",
        "        The imaginary part of the energy eigenvalues.\n",
        "    \"\"\"\n",
        "    # Step 1: Data Preparation\n",
        "    x = torch.linspace(-5,5,1000)\n",
        "    t = torch.ones_like(x)\n",
        "\n",
        "    # Step 2: Gradient Requirement\n",
        "    x.requires_grad = True\n",
        "    t.requires_grad = True\n",
        "\n",
        "    # Step 3: List Initialization\n",
        "    energy_eigenvalues_real = []\n",
        "    energy_eigenvalues_imag = []\n",
        "\n",
        "\n",
        "    for i in range(n_time_steps):\n",
        "        # Step 4: time Initialization\n",
        "        time = i/n_time_steps*period\n",
        "        t = torch.ones_like(x)*time\n",
        "\n",
        "        # Step 5: Model Prediction\n",
        "        p2_h_r, p2_h_i = compute_momentum_squared(model, x, t)\n",
        "        h_r, h_i = model(torch.cat((x.unsqueeze(1), t.unsqueeze(1)),1))\n",
        "\n",
        "        # Step 6: Integral Calculation\n",
        "        inside_integral_2= (h_r**2 + h_i**2).squeeze(1)\n",
        "        integral_2 = torch.trapz(inside_integral_2, x, dim=0)\n",
        "\n",
        "        inside_integral_1b_real = (h_r**2 +h_i**2).squeeze(1) * x**2/2\n",
        "        # inside_integral_1a_real =                                         # FILL IN\n",
        "        # inside_integral_1_real =                                          # FILL IN\n",
        "        # integral_1_real =                                                 # FILL IN    \n",
        "        energy_eigenvalue_real = integral_1_real/integral_2\n",
        "\n",
        "        # inside_integral_1a_imag =                                         # FILL IN\n",
        "        # integral_1_imag =                                                 # FILL IN\n",
        "        energy_eigenvalue_imag = integral_1_imag/integral_2\n",
        "\n",
        "        # Step 7: Array Filling\n",
        "        energy_eigenvalues_real.append(energy_eigenvalue_real.detach().numpy().astype(float))\n",
        "        energy_eigenvalues_imag.append(energy_eigenvalue_imag.detach().numpy().astype(float))\n",
        "\n",
        "    return energy_eigenvalues_real, energy_eigenvalues_imag\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84b5a4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_energy_eigenvalue(model : nn.Module):\n",
        "    \"\"\"\n",
        "    Visualize the energy eigenvalues of the Schrödinger equation.\n",
        "\n",
        "    This function visualizes the energy eigenvalues of the Schrödinger equation by using the\n",
        "    neural network model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : torch.nn.Module\n",
        "        The physics-informed neural network model.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    energy_eigenvalues_real, energy_eigenvalues_imag = compute_energy_eigenvalue(model)\n",
        "    t = np.linspace(0, period, len(energy_eigenvalues_real))\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    # Plotting real part on the left side\n",
        "    line1, = ax1.plot(t, energy_eigenvalues_real, label='Real part model prediction', marker='x', linestyle='None', color='tab:blue')\n",
        "    line2, = ax1.plot(t, 0.5 * np.ones_like(t), label='Real part true solution', color='tab:blue')\n",
        "    ax1.set_xlabel(r\"$t\\,[\\omega^{-1}]$\", fontsize=16)\n",
        "    ax1.set_ylabel(rf'$E_{shared_data.n}^r\\,[\\hbar\\omega]$', fontsize=16)\n",
        "    ax1.tick_params(axis='y', labelsize=14)\n",
        "    ax1.legend(loc='upper left', fontsize=16)\n",
        "\n",
        "\n",
        "    # Creating a twin Axes for the imaginary part on the right side\n",
        "    ax2 = ax1.twinx()\n",
        "    line3, = ax2.plot(t, energy_eigenvalues_imag, label='Imaginary part model prediction', marker='+', linestyle='None', color='tab:red')\n",
        "    line4, = ax2.plot(t, np.zeros_like(t), label='Imaginary part true solution', linestyle='--', color='tab:red')\n",
        "    ax2.set_ylabel(rf'$E_{shared_data.n}^i\\,[\\hbar\\omega]$', fontsize=16, )#color='tab:red')\n",
        "    ax2.tick_params(axis='y', labelsize=14)\n",
        "\n",
        "    # Combine lines and labels for a single legend\n",
        "    lines = [line1, line2, line3, line4]\n",
        "    labels = [line.get_label() for line in lines]\n",
        "\n",
        "    # Placing a single legend outside the frame\n",
        "    ax1.legend(lines, labels, loc='upper left', fontsize=16, bbox_to_anchor=(1.2, 0.67), borderaxespad=0.)\n",
        "\n",
        "    # Set scalar formatter with increased font size for y-axis ticks\n",
        "    ax2.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
        "    ax2.yaxis.get_major_formatter().set_powerlimits((0, 1))\n",
        "    ax2.yaxis.offsetText.set_fontsize(14)\n",
        "\n",
        "    plt.show()\n",
        "    fig.savefig(f'Energie_eigenvalue_{shared_data.n}.svg', format='svg', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2dfc904",
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_energy_eigenvalue(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29aa404f",
      "metadata": {},
      "source": [
        "# Execution task 5: Diminishing Potential \n",
        "5. __Diminishing Potential__  \n",
        "  \n",
        "    All the previous tasks could have been solved by hand using a time-evolution operator. \n",
        "    Using the PINN, however, we have a general framework that can solve the time evolution for any potential.\n",
        "    For the last step of this course, we will therefore study a non-trivial example of a time-evolving potential:\n",
        "    We start with the harmonic potential and multiply it with a time-dependent factor that decreases from 1 to 0.  \n",
        "\n",
        "    The implementation of this diminishing potential is done in 3 steps:  \n",
        "\n",
        "    1. Implement a function called `potential_scaling_function` that behaves like: $\n",
        "        A(t) = \n",
        "        \\begin{cases} \n",
        "            \\cos^2(\\frac{t}{(period)/\\pi}) & \\text{if } t < \\frac{\\text{{period}}}{2} \\\\\n",
        "            0 & \\text{otherwise}\n",
        "        \\end{cases}\n",
        "        $\n",
        "    <br><br>\n",
        "\n",
        "    2. Implement the function at the right spot into the `compute_physics_informed_loss` function.  \n",
        "    <br><br>\n",
        "\n",
        "    3. Execute the training using the same settings as before, but limit the number of epochs to `num_epochs`$=300$.  \n",
        "       Plot the result using the `SolutionVisualizer` class and save the contour plots for an evaluation.  \n",
        "       ___IMPORTANT:___  \n",
        "       __Don't__ use the `AnimationCreator`, it would overwrite your previous results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be0d830",
      "metadata": {},
      "outputs": [],
      "source": [
        "def potential_scaling_function(t:torch.Tensor, potential_scaling:bool)->torch.Tensor:\n",
        "    \"\"\"\n",
        "    This function defines the potential scaling function.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    t : torch.Tensor\n",
        "        The time values.\n",
        "    potential_scaling : bool\n",
        "        Whether the potential scaling is set to True of false.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The potential scaling function.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "498710d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_potential_scaling_function(potential_scaling):\n",
        "    \"\"\"\n",
        "    This function visualizes the potential scaling function.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    potential_scaling : bool\n",
        "        Whether the potential scaling is set to True of false.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    period = shared_data.period\n",
        "    t_tensor = torch.linspace(0, period, 100)\n",
        "    potential_scaling_result = potential_scaling_function(t_tensor, potential_scaling=potential_scaling)\n",
        "    %matplotlib inline\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    ax.plot(t_tensor, potential_scaling_result, label='Potential scaling')\n",
        "\n",
        "    ax.set_xlabel(r\"$t\\,[\\omega^{-1}]$\", fontsize=16)\n",
        "    ax.set_ylabel(r'$A(t)$', fontsize=16)\n",
        "    #ax.legend()\n",
        "\n",
        "    plt.show()\n",
        "    fig.savefig('Potential_scaling.svg', format='svg', bbox_inches='tight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52841f4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_potential_scaling_function(potential_scaling=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab283502",
      "metadata": {},
      "outputs": [],
      "source": [
        "vis = SolutionVisualizer(model=model, period=shared_data.period, potential_scaling=True, n=0, save_svg=True)\n",
        "vis.visualize()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "pinn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
